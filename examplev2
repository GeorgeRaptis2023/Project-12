import tkinter as tk
from tkinter import filedialog
import face_recognition
import cv2
from PIL import Image, ImageTk

class App():
    def __init__(self, root):
        self.root = root
        self.root.title("Ai Image Recognition")
        root.geometry("800x500")

        self.frame = tk.Frame(root)
        self.frame.grid(row=0, column=0)

        self.title = tk.Label(self.frame, text="Compare")
        self.title.grid(row=0, column=0)

        self.button = tk.Button(self.frame, text="Capture Image", command=self.capture_image)
        self.button.grid(row=0, column=1)

        self.compare_button = tk.Button(self.frame, text="Compare", command=self.compare)
        self.compare_button.grid(row=0, column=2)

        self.comparison = tk.Label(self.frame, text="")
        self.comparison.grid(row=12, column=0, columnspan=8)

        self.result1 = tk.Label(self.frame, text="")
        self.result1.grid(row=3, column=0, columnspan=4)

        self.face1 = tk.Label(self.frame)
        self.face1.grid(row=4, column=0, columnspan=2, rowspan=2)

        self.face2 = tk.Label(self.frame)
        self.face2.grid(row=4, column=2, columnspan=2, rowspan=2)

        self.tolerance1_label = tk.Label(self.frame, text="Tolerance:")
        self.tolerance1_label.grid(row=0, column=3, padx=(10, 0))

        self.option_numjitters1_label = tk.Label(self.frame, text="Num Jitters:")
        self.option_numjitters1_label.grid(row=0, column=4, padx=(10, 0))

        self.tolerance1 = tk.Scale(self.frame, from_=1, to=100, tickinterval=5, orient="horizontal")
        self.tolerance1.grid(row=0, column=5)

        self.option_numjitters1 = tk.Scale(self.frame, from_=1, to=20, tickinterval=5, orient="horizontal")
        self.option_numjitters1.grid(row=0, column=6)

        self.option_size1 = tk.Listbox(self.frame, height=3, exportselection=False)
        self.option_size1.grid(row=2, column=1)
        self.option_size1.insert(1, "large")
        self.option_size1.insert(2, "small")

        self.option_type1 = tk.Listbox(self.frame, height=3, exportselection=False)
        self.option_type1.grid(row=2, column=2)
        self.option_type1.insert(1, "hog")
        self.option_type1.insert(2, "cnn")

        self.result2 = tk.Label(self.frame, text="")
        self.result2.grid(row=9, column=0, columnspan=4)

        self.face3 = tk.Label(self.frame)
        self.face3.grid(row=10, column=0, columnspan=2, rowspan=2)

        self.face4 = tk.Label(self.frame)
        self.face4.grid(row=10, column=2, columnspan=2, rowspan=2)

        self.tolerance2_label = tk.Label(self.frame, text="Tolerance:")
        self.tolerance2_label.grid(row=6, column=3, padx=(10, 0))

        self.option_numjitters2_label = tk.Label(self.frame, text="Num Jitters:")
        self.option_numjitters2_label.grid(row=6, column=4, padx=(10, 0))

        self.tolerance2 = tk.Scale(self.frame, from_=1, to=100, tickinterval=5, orient="horizontal")
        self.tolerance2.grid(row=6, column=5)

        self.option_numjitters2 = tk.Scale(self.frame, from_=1, to=20, tickinterval=5, orient="horizontal")
        self.option_numjitters2.grid(row=6, column=6)

        self.option_size2 = tk.Listbox(self.frame, height=3, exportselection=False)
        self.option_size2.grid(row=8, column=1)
        self.option_size2.insert(1, "large")
        self.option_size2.insert(2, "small")

        self.option_type2 = tk.Listbox(self.frame, height=3, exportselection=False)
        self.option_type2.grid(row=8, column=2)
        self.option_type2.insert(1, "hog")
        self.option_type2.insert(2, "cnn")

        self.facial_recognition_app = self.init_facial_recognition_app()

    def init_facial_recognition_app(self):
        facial_root = tk.Toplevel(self.root)
        return FacialRecognitionApp(facial_root, self)

    def capture_image(self):
        ret, frame = self.facial_recognition_app.vid.read()
        if ret:
            file_location = "captured_image.jpg"
            cv2.imwrite(file_location, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            self.facial_recognition_app.location_input.delete(0, tk.END)
            self.facial_recognition_app.location_input.insert(0, file_location)

    def compare(self):
        self.facial_recognition_app.compare()

        try:
            encoding_size = self.option_size1.curselection()[0]
            model_type = self.option_type1.curselection()[0]
            tolerance = self.tolerance1.get() / 100
            numjitters = self.option_numjitters1.get()
        except:
            print("Wrong Selection")
            return

        try:
            self.image1, self.image2, time1, distance1 = self.facial_recognition_app.recognize(
                encoding_size, model_type, tolerance, numjitters, self.facial_recognition_app.location_input.get(),
                "me.jpg", self.result1)
            self.face1['image'], self.face2['image'] = self.image1, self.image2
        except:
            print('Failed')
            return

        try:
            encoding_size = self.option_size2.curselection()[0]
            model_type = self.option_type2.curselection()[0]
            tolerance = self.tolerance2.get() / 100
            numjitters = self.option_numjitters2.get()
        except:
            print("Wrong Selection")
            return

        try:
            self.image3, self.image4, time2, distance2 = self.facial_recognition_app.recognize(
                encoding_size, model_type, tolerance, numjitters, self.facial_recognition_app.location_input.get(),
                "me.jpg", self.result2)
            self.face3['image'], self.face4['image'] = self.image3, self.image4
        except:
            print('Failed')
            return

        comptext = ""
        if (abs(time1 - time2) < 0.01):
            comptext += f"Both processes took about the same time ."
        elif (time1 > time2):
            comptext += f"The second process was faster by {time1 - time2} ms ."
        else:
            comptext += f"The first process was faster by {time2 - time1} ms ."
        if (abs(distance1 - distance2) < 0.01):
            comptext += f"Both processes found about the same distance"
        elif (distance2 > distance1):
            comptext += f"The first process found a smaller distance by {distance2[0] - distance1[0]} "
        else:
            comptext += f"The second process  process found a smaller distance by {distance1[0] - distance2[0]}"
        self.comparison.configure(text=comptext)


class FacialRecognitionApp():
    def __init__(self, root, app):
        self.root = root
        self.root.title("Facial Recognition App")
        root.geometry("600x400")

        self.app = app

        self.frame = tk.Frame(root)
        self.frame.grid(row=0, column=0)

        self.title = tk.Label(self.frame, text="Facial Recognition")
        self.title.grid(row=0, column=0)

        self.video_source = 0
        self.vid = cv2.VideoCapture(self.video_source)

        self.canvas = tk.Canvas(self.frame, width=self.vid.get(cv2.CAP_PROP_FRAME_WIDTH),
                                height=self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.canvas.grid(row=1, column=0, columnspan=3)

        self.location_input = tk.Entry(self.frame, width=25)
        self.location_input.grid(row=2, column=1)

        self.browse_button = tk.Button(self.frame, text="Select File", command=self.select_file)
        self.browse_button.grid(row=2, column=0)

        self.compare_button = tk.Button(self.frame, text="Compare", command=self.compare)
        self.compare_button.grid(row=2, column=2)

        self.result_label = tk.Label(self.frame, text="Result:")
        self.result_label.grid(row=3, column=0)

        self.result = tk.Label(self.frame, text="")
        self.result.grid(row=3, column=1)

        self.update()

    def select_file(self):
        file_location = filedialog.askopenfilename(initialdir="/", title="Select a File")
        if file_location:
            self.location_input.delete(0, tk.END)
            self.location_input.insert(0, file_location)

    def compare(self):
        file_location = self.location_input.get()

        try:
            known_image = face_recognition.load_image_file("me.jpg")
            unknown_image = face_recognition.load_image_file(file_location)

            me_encoding = face_recognition.face_encodings(known_image)[0]
            unknown_encoding = face_recognition.face_encodings(unknown_image)[0]

            result = face_recognition.compare_faces([me_encoding], unknown_encoding)
            self.result.configure(text="Match" if result[0] else "No Match")

        except Exception as e:
            self.result.configure(text=f"Error: {str(e)}")

    def update(self):
        ret, frame = self.vid.read()
        if ret:
            photo = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))
            self.canvas.create_image(0, 0, image=photo, anchor=tk.NW)
            self.canvas.photo = photo
        self.root.after(10, self.update)

    def recognize(self, encoding_size, model_type, tolerance, numjitters, filelocation1, filelocation2, text):
        if encoding_size:
            encoding_size = "small"
        else:
            encoding_size = "large"
        if model_type:
            model_type = "cnn"
        else:
            model_type = "hog"
        t_start = time.process_time()

        first_image = face_recognition.load_image_file(filelocation1)
        second_image = face_recognition.load_image_file(filelocation2)

        face_locations1 = face_recognition.face_locations(first_image, model=model_type)
        face_locations2 = face_recognition.face_locations(second_image, model=model_type)

        first_encoding = face_recognition.face_encodings(first_image, model=encoding_size,
                                                         known_face_locations=face_locations1, num_jitters=numjitters)[0]
        second_encoding = face_recognition.face_encodings(second_image, model=encoding_size,
                                                          known_face_locations=face_locations2, num_jitters=numjitters)[0]

        result = face_recognition.compare_faces([first_encoding], second_encoding, tolerance=tolerance)
        distance = face_recognition.api.face_distance([first_encoding], second_encoding)

        t_process_ms = 1000 * (time.process_time() - t_start)
        if result[0]:
            answer = "Recognized"
        else:
            answer = "Failed"
        text.configure(text=f"Result: {answer} in {t_process_ms:.2f} ms with distance {distance[0]:.2f}")
        top, right, bottom, left = face_locations1[0]
        face_image = first_image[top:bottom, left:right]
        pil_image = Image.fromarray(face_image)
        pil_image = pil_image.resize((75, 75))
        top, right, bottom, left = face_locations2[0]
        face_image2 = second_image[top:bottom, left:right]
        pil_image2 = Image.fromarray(face_image2)
        pil_image2 = pil_image2.resize((75, 75))
        return ImageTk.PhotoImage(pil_image), ImageTk.PhotoImage(pil_image2), t_process_ms, distance


if __name__ == "__main__":
    import time

    root = tk.Tk()
    app = App(root)
    root.mainloop()
